{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Input,BatchNormalization,LeakyReLU\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.color import lab2rgb, rgb2lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_single_dim_from_LAB_convert_to_RGB(image,idim):\n",
    "        '''\n",
    "        image is a single lab image of shape (None,None,3)\n",
    "        '''\n",
    "        z = np.zeros(image.shape)\n",
    "        if idim != 0 :\n",
    "            z[:,:,0]=80 ## I need brightness to plot the image along 1st or 2nd axis\n",
    "        z[:,:,idim] = image[:,:,idim]\n",
    "        z = lab2rgb(z)\n",
    "        return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePath=\"./TESTSimpleColor/TemporalDataSet/dataset_updated/training_set/painting/\"\n",
    "\n",
    "\n",
    "image = img_to_array(load_img(ImagePath+\"0001.jpg\",target_size=(224,224))) / 255\n",
    "lab_image = rgb2lab(image)\n",
    "lab_image_norm = (lab_image + [0, 128, 128]) / [100, 255, 255]\n",
    "\n",
    "print(lab_image.shape)\n",
    "\n",
    "lab_l = extract_single_dim_from_LAB_convert_to_RGB(lab_image,0)\n",
    "lab_a = extract_single_dim_from_LAB_convert_to_RGB(lab_image,1)\n",
    "lab_db = extract_single_dim_from_LAB_convert_to_RGB(lab_image,2)\n",
    "    \n",
    "        # Plot the results\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "data = [('L: lightness', lab_l), ('a: green-magenta channel', lab_a), ('b: blue-yellow channel', lab_db)]\n",
    "    \n",
    "for ax, (title, img) in zip(axes, data):\n",
    "            ax.set_title(title)\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"./TESTSimpleColor/TemporalDataSet/dataset_updated/\"))\n",
    "\n",
    "\n",
    "\n",
    "HEIGHT=224\n",
    "WIDTH=224\n",
    "ImagePath=\"./TESTSimpleColor/TemporalDataSet/dataset_updated/training_set/painting/\"\n",
    "\n",
    "def ExtractInput(path):\n",
    "    X_img=[]\n",
    "    y_img=[]\n",
    "    for imageDir in os.listdir(ImagePath):\n",
    "        try:\n",
    "            image = img_to_array(load_img(ImagePath+\"0001.jpg\",target_size=(224,224))) / 255\n",
    "            lab_image = rgb2lab(image)\n",
    "            lab_image_norm = (lab_image + [0, 128, 128]) / [100, 255, 255]\n",
    "            X_img.append(lab_image_norm[:,:,0])\n",
    "            y_img.append(lab_image_norm[:,:,1:])\n",
    "        except:\n",
    "            pass\n",
    "    X_img = np.array(X_img)\n",
    "    y_img = np.array(y_img)\n",
    "    \n",
    "    return X_img,y_img\n",
    "\n",
    "x_train,y_train = ExtractInput(ImagePath)\n",
    "\n",
    "def GenerateInputs(X_,y_):\n",
    "    X_ = list(map(lambda x: x.reshape(1,224,224,1),X_))\n",
    "    y_ = list(map(lambda x: x.reshape(1,224,224,2),y_))\n",
    "    return X_,y_\n",
    "\n",
    "x_train,y_train = GenerateInputs(x_train,y_train)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = Sequential([\n",
    "    Input(shape=(HEIGHT, WIDTH,1)),\n",
    "    Conv2D(16,(3,3),padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    Conv2D(32,(3,3),padding='same',strides=1),\n",
    "    Conv2D(32,(3,3),padding='same',strides=1),\n",
    "    \n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2,2),padding='same'),\n",
    "    \n",
    "    Conv2D(64,(3,3),padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2,2),padding='same'),\n",
    "    \n",
    "    Conv2D(128,(3,3),padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(256,(3,3),padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(128,(3,3),padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64,(3,3), padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    \n",
    "    Conv2D(64,(3,3), padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(32,(3,3),padding='same',strides=1),\n",
    "    LeakyReLU(),\n",
    "    #BatchNormalization(),\n",
    "    \n",
    "    Conv2D(2,(3,3), activation='tanh',padding='same',strides=1),\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise = x_train[1]\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "img = np.zeros((WIDTH,HEIGHT,3)).reshape(224,224,3)\n",
    "print(img.shape)\n",
    "img[:,:,0] =x_train[0].reshape(224,224)\n",
    "img[:,:,1:] = generated_image.numpy().reshape(224,224,2)\n",
    "img = (img * [100,255,255]) - [0,128,128]\n",
    "rgb_img = lab2rgb(img)\n",
    "plt.imshow(rgb_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        Input(shape=(HEIGHT, WIDTH,2)),\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(224,224,1))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan\n",
    "gan = create_gan(discriminator,generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i,(lmap,img) in enumerate(list(zip(test_input,predictions))):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      img = np.zeros((WIDTH,HEIGHT,3)).reshape(224,224,3)\n",
    "      \n",
    "      img[:,:,0] =lmap.reshape(224,224)\n",
    "      img[:,:,1:] = img.reshape(224,224,2)\n",
    "      img = (img * [100,255,255]) - [0,128,128]\n",
    "      rgb_img = lab2rgb(img)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "      plt.imshow(rgb_img)\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "seed = x_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epochs=1, batch_size=128):\n",
    "    \n",
    "    #Loading the data\n",
    "    \n",
    "    \n",
    "    # Creating GAN\n",
    "    generator= make_generator_model()\n",
    "    discriminator= make_discriminator_model()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    \n",
    "    for e in range(1,epochs+1 ):\n",
    "        print(\"Epoch %d\" %e)\n",
    "        for _ in tqdm(range(batch_size)):\n",
    "        #generate  random noise as an input  to  initialize the  generator\n",
    "            A = len(x_train)\n",
    "            image_batch =x_train[np.random.randint(low=0,high=A,size=batch_size)]\n",
    "                \n",
    "            # Generate fake MNIST images from noised input\n",
    "            generated_images = generator.predict(image_batch)\n",
    "            \n",
    "            # Get a random set of  real images\n",
    "            \n",
    "            \n",
    "            #Construct different batches of  real and fake data \n",
    "            X= np.concatenate([image_batch, generated_images])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis=np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size]=0.9\n",
    "            \n",
    "            #Pre train discriminator on  fake and real data  before starting the gan. \n",
    "            discriminator.trainable=True\n",
    "            discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Tricking the noised input of the Generator as real data\n",
    "            image_batch2 =x_train[np.random.randint(low=0,high=A,size=batch_size)]\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            # During the training of gan, \n",
    "            # the weights of discriminator should be fixed. \n",
    "            #We can enforce that by setting the trainable flag\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #training  the GAN by alternating the training of the Discriminator \n",
    "            #and training the chained GAN model with Discriminator’s weights freezed.\n",
    "            gan.train_on_batch(image_batch2, y_gen)\n",
    "            \n",
    "        if e == 1 or e % 2 == 0:\n",
    "           \n",
    "            generate_and_save_images( generator,e,seed)\n",
    "training(10,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce38e80e5198e1a528032d773ef998b5a6815c06ae2381a5a6ff105db93cfe61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
